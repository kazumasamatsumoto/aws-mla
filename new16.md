# AWS機械学習関連用語解説

## AWS Glue DataBrew の min-max 正規化

AWS Glue DataBrewのmin-max正規化は、データの値を特定の範囲（通常は0〜1）にスケーリングする正規化手法です。異なるスケールの特徴を比較可能にし、機械学習モデルの性能向上に貢献する重要なデータ前処理技術です。

### 基本概念

- **定義**: 特徴量の値を指定された範囲（通常は0〜1）に線形変換する技術
- **数式**: X_normalized = (X - X_min) / (X_max - X_min)
- **目的**: 異なるスケールの特徴量を同じ範囲に変換し、比較可能にする

### 主な特徴

- **範囲保存**: 元のデータの相対的な関係性を保持
- **外れ値の影響**: 最小値と最大値に基づくため、外れ値の影響を受けやすい
- **線形変換**: 線形関係を保持する変換
- **カスタム範囲**: 0〜1以外の任意の範囲への変換も可能（例: -1〜1）
- **特徴間の均等化**: 異なるスケールの特徴を同じ範囲に揃える
- **視覚的解釈**: 変換後のデータが直感的に解釈しやすい
- **AWS Glue DataBrew統合**: ノーコードインターフェースでの簡単な適用

### AWS Glue DataBrewでの実装

- **変換ステップ**: レシピステップとしてmin-max正規化を追加
- **パラメータ設定**: 目標範囲（デフォルトは0〜1）の指定
- **列選択**: 正規化を適用する数値列の選択
- **プロファイリング**: 変換前後のデータ分布の視覚化
- **レシピの保存と共有**: 再利用可能な変換レシピとしての保存
- **ジョブスケジューリング**: 定期的なデータ処理ジョブとしての実行
- **データ品質検証**: 変換結果の品質チェック

### 利点

- **勾配降下法の収束改善**: 最適化アルゴリズムの収束速度向上
- **特徴の重要度均等化**: 異なるスケールの特徴の影響を均等化
- **距離ベースアルゴリズムの改善**: k近傍法やクラスタリングなどの性能向上
- **ニューラルネットワークの学習効率**: 活性化関数の効果的な利用範囲への適合
- **解釈可能性**: 0〜1の範囲での直感的な理解のしやすさ
- **視覚化の改善**: 異なるスケールの特徴の視覚的比較の容易化
- **モデル安定性の向上**: 数値的安定性の改善

### 考慮事項と注意点

- **外れ値の影響**: 極端な値による変換範囲の歪み
- **分布の変化**: 元のデータ分布の特性が変わる可能性
- **ゼロ分散問題**: すべての値が同じ場合の除算エラー
- **テストデータの変換**: 訓練データと同じパラメータでの変換の必要性
- **動的範囲の変化**: 時間経過によるデータ範囲の変化への対応
- **特徴の重要性**: 正規化による特徴の相対的重要性への影響
- **他の正規化手法との比較**: 標準化（Z-score）など他の手法との適切な選択

### 一般的なユースケース

- **ニューラルネットワーク**: 入力特徴の前処理としての利用
- **距離ベースアルゴリズム**: k近傍法、k-means、SVM等での特徴スケーリング
- **画像処理**: ピクセル値の正規化（0〜255から0〜1へ）
- **推薦システム**: ユーザー評価スコアの正規化
- **異常検出**: 異なるセンサーデータの統一スケールでの比較
- **時系列分析**: 異なるスケールの時系列データの比較
- **特徴量エンジニアリングパイプライン**: 機械学習前処理ワークフローの一部

## 正規化と標準化

正規化と標準化は、データ前処理技術で、特徴の値を一定の範囲や分布に変換します。正規化は値を0〜1の範囲に、標準化は平均0、標準偏差1の分布に変換します。両者は異なる特性を持ち、用途に応じて適切に選択することが重要です。

### 基本概念

#### 正規化（Normalization）
- **定義**: データを特定の範囲（通常は0〜1）にスケーリングする技術
- **数式**: X_normalized = (X - X_min) / (X_max - X_min)
- **別名**: Min-Max Scaling

#### 標準化（Standardization）
- **定義**: データを平均0、標準偏差1の分布に変換する技術
- **数式**: X_standardized = (X - μ) / σ
- **別名**: Z-score Normalization

### 主な特徴と比較

| 特性 | 正規化 | 標準化 |
|------|--------|--------|
| 結果範囲 | 固定範囲（通常0〜1） | 理論上は無制限（実際は大部分が-3〜3） |
| 外れ値の影響 | 大きい（最小/最大値に依存） | 小さい（平均と標準偏差に基づく） |
| 分布の保存 | 形状は保存、範囲が変化 | 平均と分散が変換、形状は保存 |
| 適したデータ | 一様分布、正規分布でないデータ | 正規分布に近いデータ |
| 適したアルゴリズム | ニューラルネットワーク、k-NN | 線形回帰、ロジスティック回帰、SVM |

### 実装方法

#### AWS Glue DataBrew
- **正規化**: Min-Max変換ステップの適用
- **標準化**: Z-score変換ステップの適用

#### Amazon SageMaker
- **組み込み前処理**: 多くのアルゴリズムで自動スケーリングオプション
- **SageMaker Processing**: カスタム前処理ジョブでの実装
- **SageMaker Feature Store**: 変換済み特徴の保存と再利用

#### Python ライブラリ
- **Scikit-learn**: MinMaxScaler と StandardScaler クラス
- **TensorFlow**: tf.keras.layers.Normalization
- **PyTorch**: torchvision.transforms.Normalize

### 選択基準

- **データ分布**: 正規分布に近いデータは標準化が適切
- **外れ値の存在**: 外れ値が多い場合は標準化が堅牢
- **アルゴリズム要件**: 特定のアルゴリズムの推奨に従う
- **特徴の性質**: 異なる単位や範囲を持つ特徴の統一
- **解釈可能性**: 0〜1の範囲が望ましい場合は正規化
- **モデルの収束性**: 勾配降下法の収束特性への影響
- **ドメイン知識**: 特定の分野での標準的な前処理方法

### 利点

#### 正規化の利点
- **直感的な解釈**: 0〜1の範囲での理解しやすさ
- **画像処理との親和性**: ピクセル値の自然な表現
- **境界のある活性化関数**: シグモイドやtanhなどとの相性
- **異なる特徴の比較**: 統一スケールでの視覚化と比較

#### 標準化の利点
- **外れ値への堅牢性**: 極端な値の影響を軽減
- **正規分布の仮定**: 多くの統計手法との親和性
- **勾配降下法の効率**: 収束速度の向上
- **特徴の重要度保存**: 相対的な変動の保存

### 一般的なユースケース

#### 正規化の用途
- **ニューラルネットワーク**: 特に出力層が0〜1の範囲の場合
- **画像処理**: ピクセル値のスケーリング
- **推薦システム**: ユーザー評価や類似度スコア
- **可視化**: 異なるスケールのデータの比較表示

#### 標準化の用途
- **線形モデル**: 線形回帰、ロジスティック回帰
- **主成分分析(PCA)**: 分散に基づく次元削減
- **クラスタリング**: k-meansなどの距離ベースアルゴリズム
- **異常検出**: 統計的手法に基づく外れ値検出

## Amazon SageMaker のエンドポイントのバリアント機能

Amazon SageMaker のエンドポイントのバリアント機能は、同じエンドポイントで複数のモデルバージョンをデプロイし、トラフィックを分散させる機能です。A/Bテストやブルー/グリーンデプロイメントに活用でき、モデルの段階的な更新や実験を安全に行うことができます。

### 基本概念

- **定義**: 単一のエンドポイントで複数のモデルバージョンを同時に提供する機能
- **目的**: モデル更新の安全な実施、実験、トラフィック管理
- **構成要素**: 本番バリアント（各モデルバージョン）とトラフィック分散ルール

### 主な特徴

- **複数モデルのホスティング**: 同一エンドポイントでの複数モデルの同時提供
- **トラフィック分散**: パーセンテージベースのトラフィック割り当て
- **インスタンスタイプの混在**: 各バリアントに異なるインスタンスタイプの割り当て
- **自動スケーリング**: バリアントごとの独立した自動スケーリング設定
- **モニタリング**: バリアントごとのパフォーマンスと利用状況の監視
- **シャドウモード**: 本番トラフィックに影響を与えずに新モデルの評価
- **動的更新**: エンドポイントを停止せずにトラフィック配分の変更

### デプロイパターン

- **A/Bテスト**: 複数モデルバージョンの性能比較
- **ブルー/グリーンデプロイメント**: リスクを最小化した安全なモデル更新
- **カナリアデプロイメント**: 少量のトラフィックでの新モデルの検証
- **シャドウテスト**: 実際のリクエストを使用した新モデルの評価（結果は返さない）
- **チャンピオン/チャレンジャー**: 現行最良モデルと新モデルの比較
- **機能フラグ**: 特定のユーザーセグメントへの新機能の提供
- **段階的ロールアウト**: 徐々にトラフィックを新モデルに移行

### 実装方法

- **CreateEndpointConfig API**: 複数の本番バリアントの定義
- **UpdateEndpoint API**: 既存エンドポイントの構成更新
- **CreateEndpoint API**: 新しいエンドポイント構成でのエンドポイント作成
- **SageMaker コンソール**: GUIを通じたバリアント設定
- **AWS SDK**: プログラムによるバリアント管理
- **AWS CloudFormation**: インフラストラクチャとしてのバリアント設定
- **SageMaker Python SDK**: Pythonコードでのバリアント管理

### トラフィック分散方法

- **固定分散**: 事前定義された固定比率でのトラフィック分散
- **動的分散**: パフォーマンスメトリクスに基づく自動調整
- **コンテキストベース**: リクエスト属性に基づく特定バリアントへのルーティング
- **ユーザーセグメント**: ユーザー特性に基づくバリアント割り当て
- **地理的分散**: 地域に基づくトラフィック割り当て
- **時間ベース**: 時間帯に応じたトラフィック配分の変更
- **段階的移行**: 徐々にトラフィックを新バリアントに移行

### 利点

- **リスク軽減**: 新モデルの段階的な導入によるリスク管理
- **継続的な改善**: 実験と検証に基づくモデル改善サイクル
- **ダウンタイムなし**: エンドポイントを停止せずにモデル更新
- **コスト最適化**: 各バリアントに適したインスタンスタイプの選択
- **パフォーマンス比較**: 実際のトラフィックでのモデル性能評価
- **迅速なロールバック**: 問題発生時の素早い元のバージョンへの復帰
- **ユーザーエクスペリエンスの一貫性**: エンドポイントURLの維持

### 一般的なユースケース

- **モデルアップグレード**: 新しいアルゴリズムやアーキテクチャへの移行
- **特徴量エンジニアリングの検証**: 新しい特徴セットの効果検証
- **ハイパーパラメータ最適化**: 異なるハイパーパラメータ設定の比較
- **アルゴリズム比較**: 異なるアルゴリズムの実環境での性能比較
- **モデル更新頻度の検証**: 再トレーニング頻度の最適化
- **インスタンスタイプの最適化**: コストとパフォーマンスのバランス検証
- **ビジネス指標への影響測定**: モデル変更のビジネス成果への影響評価

## ロジスティック回帰（Logistic regression）

ロジスティック回帰は、分類問題に使用される統計モデルで、入力特徴と二値（または多クラス）出力の関係をモデル化します。シンプルで解釈しやすい特性があり、機械学習の基本的なアルゴリズムとして広く使用されています。

### 基本概念

- **定義**: 確率を予測するための線形モデルにロジスティック関数を適用した統計手法
- **目的**: 二値分類（拡張して多クラス分類）問題の解決
- **数学的基礎**: ロジスティック関数（シグモイド関数）を用いた確率モデリング

### 主な特徴

- **確率出力**: 0〜1の範囲の確率値として予測を出力
- **決定境界**: 特徴空間内の線形決定境界を形成
- **線形モデル**: 基本的には線形モデルの拡張
- **最尤推定**: パラメータ推定に最尤法を使用
- **正則化オプション**: 過学習防止のためのL1/L2正則化
- **解釈可能性**: 係数の解釈が直感的で容易
- **計算効率**: 訓練と予測が比較的高速

### 数学的フレームワーク

- **ロジスティック関数**: f(z) = 1 / (1 + e^(-z))
- **線形予測子**: z = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ
- **確率モデル**: P(Y=1|X) = 1 / (1 + e^(-(β₀ + β₁x₁ + ... + βₙxₙ)))
- **損失関数**: 交差エントロピー損失（対数尤度の負）
- **最適化**: 勾配降下法、ニュートン法などによるパラメータ最適化
- **多クラス拡張**: ソフトマックス関数を用いた多項ロジスティック回帰
- **正則化項**: L1（Lasso）またはL2（Ridge）正則化による過学習防止

### Amazon SageMakerでの実装

- **組み込みアルゴリズム**: SageMakerの組み込みロジスティック回帰アルゴリズム
- **ハイパーパラメータ**: 学習率、正則化パラメータ、最適化アルゴリズムなどの調整
- **分散トレーニング**: 大規模データセットでの分散トレーニングサポート
- **自動モデル調整**: ハイパーパラメータの自動最適化
- **推論最適化**: 効率的な推論のためのモデル最適化
- **特徴処理**: カテゴリ変数の自動エンコーディングなどの前処理
- **モデル説明可能性**: SageMaker Clarifyとの統合による解釈

### 利点

- **解釈可能性**: 係数の大きさと符号から特徴の影響を直接解釈可能
- **効率性**: 訓練と予測が計算効率に優れている
- **確率出力**: クラス所属の確率を直接提供
- **過学習耐性**: 適切な正則化を適用することで比較的過学習しにくい
- **スケーラビリティ**: 大規模データセットにも適用可能
- **拡張性**: 多クラス分類への自然な拡張
- **統計的基盤**: 確立された統計理論に基づく堅牢性

### 制限事項

- **線形決定境界**: 非線形関係のモデル化には限界がある
- **特徴エンジニアリング依存**: 複雑な関係の捕捉には特徴エンジニアリングが必要
- **クラス不均衡感度**: クラス不均衡データでの性能低下
- **多重共線性問題**: 高相関特徴による不安定性
- **外れ値感度**: 外れ値の影響を受けやすい
- **高次元データでの課題**: 特徴数が多い場合の過学習リスク
- **複雑な相互作用の捕捉**: 特徴間の複雑な相互作用のモデル化が困難

### 一般的なユースケース

- **顧客離反予測**: 顧客が解約する確率の予測
- **クレジットスコアリング**: ローン返済能力の評価
- **医療診断**: 疾患リスクの評価
- **マーケティング効果**: 広告キャンペーンの反応予測
- **スパム検出**: メールやコメントのスパム分類
- **センチメント分析**: テキストの感情分類
- **リスク評価**: 様々な領域でのリスク確率の推定

## 線形回帰（Linear regression）

線形回帰は、連続値の予測に使用される統計モデルで、入力特徴と出力の間の線形関係をモデル化します。シンプルで計算効率が高く、解釈しやすい特性があり、予測モデリングの基礎となる重要なアルゴリズムです。

### 基本概念

- **定義**: 入力変数と出力変数の間の線形関係をモデル化する統計手法
- **目的**: 連続値の予測（回帰問題の解決）
- **数学的基礎**: 最小二乗法に基づくパラメータ推定

### 主な特徴

- **線形関係**: 入力特徴と出力の間の線形関係を仮定
- **連続出力**: 任意の実数値を予測可能
- **パラメータ解釈**: 各係数が対応する特徴の影響度を表す
- **閉形式解**: 小〜中規模データでは直接計算可能な解析解
- **正則化バリエーション**: Ridge、Lasso、Elastic Netなどの拡張
- **計算効率**: 訓練と予測が非常に高速
- **基礎的モデル**: より複雑なモデルの基礎となる概念

### 数学的フレームワーク

- **線形モデル**: y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙ + ε
- **行列表記**: Y = Xβ + ε
- **最小二乗解**: β = (X^T X)^(-1) X^T Y
- **損失関数**: 平均二乗誤差（MSE）
- **最適化**: 勾配降下法または正規方程式による解法
- **Ridge正則化**: L2ノルムペナルティ（β^T β）の追加
- **Lasso正則化**: L1ノルムペナルティ（|β|）の追加

### Amazon SageMakerでの実装

- **組み込みアルゴリズム**: SageMakerの線形学習器アルゴリズム
- **ハイパーパラメータ**: 学習率、正則化パラメータ、最適化アルゴリズムなどの調整
- **分散トレーニング**: 大規模データセットでの効率的な分散処理
- **自動モデル調整**: ハイパーパラメータの自動最適化
- **特徴処理**: 数値特徴の自動スケーリング、カテゴリ変数の処理
- **モデル説明可能性**: SageMaker Clarifyとの統合
- **モデルモニタリング**: デプロイ後のモデルパフォーマンス監視

### 利点

- **解釈可能性**: 係数の直接的な解釈が可能
- **計算効率**: 訓練と予測が非常に高速
- **少ないデータでも機能**: 比較的少量のデータでも学習可能
- **過学習耐性**: 適切な正則化を適用することで過学習を抑制
- **スケーラビリティ**: 大規模データセットにも適用可能
- **統計的推論**: 係数の信頼区間や仮説検定が可能
- **基礎的理解**: 複雑なモデルの基礎となる概念

### 制限事項

- **線形関係の仮定**: 非線形関係のモデル化には限界がある
- **外れ値感度**: 外れ値の影響を強く受ける
- **多重共線性問題**: 高相関特徴による不安定性
- **分布の仮定**: 誤差項の正規性など特定の仮定に基づく
- **特徴エンジニアリング依存**: 複雑な関係の捕捉には特徴エンジニアリングが必要
- **因果関係の混同**: 相関関係と因果関係の区別が必要
- **複雑な相互作用**: 特徴間の複雑な相互作用のモデル化が困難

### 一般的なユースケース

- **価格予測**: 不動産価格、製品価格の予測
- **需要予測**: 製品需要、リソース需要の予測
- **財務分析**: 売上予測、コスト分析
- **トレンド分析**: 時系列データの線形トレンド抽出
- **影響要因分析**: 結果に対する各要因の影響度評価
- **品質管理**: 製造プロセスの品質予測
- **リソース割り当て**: 必要リソースの予測に基づく割り当て
