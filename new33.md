# AWS機械学習関連用語解説

## オーバーサンプリング
少数クラスのサンプルを増やして、クラス不均衡を解消する手法です。モデルが少数クラスの特徴を学習しやすくなります。

**主な特徴:**
- 少数クラスのサンプル数を増加させる
- クラス分布のバランスを改善
- 少数クラスの検出精度を向上
- データ量を増やすことでモデルの学習を強化
- 元のデータ分布を変更する

**実装方法:**
- SageMaker Processing ジョブでの前処理
- imbalanced-learn ライブラリの RandomOverSampler
- カスタム Python スクリプトでの実装
- AWS Glue ETL ジョブでのデータ変換
- SageMaker Data Wrangler での処理

**考慮事項:**
- 過学習のリスク（特に単純な複製の場合）
- 計算コストとメモリ使用量の増加
- 人工的なデータ生成の品質管理
- テストデータへの適用は避ける（データリーク防止）
- 評価メトリクスへの影響

**ユースケース:**
- 不正検知（少数の不正トランザクション）
- 医療診断（希少疾患の検出）
- 顧客解約予測（少数の解約顧客）
- 異常検知（少数の異常イベント）
- リスク管理（少数の高リスクケース）

## ランダムオーバーサンプリング
少数クラスからランダムにサンプルを複製して、クラス不均衡を解消する単純な手法です。実装が容易ですが、過学習のリスクがあります。

**主な特徴:**
- 少数クラスのサンプルをランダムに複製
- 実装が非常に簡単
- 追加の計算リソースが最小限
- データ分布を変更せず、単純に複製
- どのような種類のデータにも適用可能

**実装方法:**
```python
# imbalanced-learn を使用した実装例
from imblearn.over_sampling import RandomOverSampler
ros = RandomOverSampler(random_state=42)
X_resampled, y_resampled = ros.fit_resample(X, y)
```

**長所と短所:**
- **長所:**
  - 実装が容易で直感的
  - 計算コストが低い
  - 元のデータ分布を保持
  - どのようなデータタイプにも適用可能
  
- **短所:**
  - 過学習のリスクが高い
  - 新しい情報を追加しない
  - 決定境界の一般化能力が低下する可能性
  - 同じデータポイントの重複による冗長性

**ユースケース:**
- 小規模データセットでの初期実験
- 計算リソースが限られている環境
- ベースラインモデルの構築
- 他のサンプリング手法との比較
- 簡易的なクラス不均衡対策

## ランダムアンダーサンプリング
多数クラスからランダムにサンプルを削除して、クラス不均衡を解消する手法です。データ量が減少するため、情報損失のリスクがあります。

**主な特徴:**
- 多数クラスのサンプルをランダムに削除
- データセットのサイズを縮小
- 処理速度と効率の向上
- メモリ使用量の削減
- クラス分布の均等化

**実装方法:**
```python
# imbalanced-learn を使用した実装例
from imblearn.under_sampling import RandomUnderSampler
rus = RandomUnderSampler(random_state=42)
X_resampled, y_resampled = rus.fit_resample(X, y)
```

**長所と短所:**
- **長所:**
  - 計算効率が良い
  - 過学習のリスクを軽減
  - トレーニング時間の短縮
  - メモリ使用量の削減
  
- **短所:**
  - 重要な情報の損失リスク
  - データ利用効率の低下
  - 多様性の減少
  - モデル性能の不安定化

**改良版アンダーサンプリング手法:**
- Tomek リンクの除去
- 近傍クリーニングルール（NCR）
- 編集最近傍法（ENN）
- クラスタリングベースのアンダーサンプリング
- インスタンス難易度に基づくサンプリング

**ユースケース:**
- 大規模データセットの処理
- 計算リソースが限られている環境
- 初期プロトタイピングと実験
- 多数クラスに冗長性が高い場合
- アンサンブル学習との組み合わせ

## Synthetic Minority Oversampling Technique（SMOTE）
少数クラスの既存サンプル間を補間して新しいサンプルを生成する手法です。単純な複製よりも多様性のあるサンプルを生成できます。

**主な特徴:**
- 少数クラスの近接サンプル間で線形補間
- 人工的な新サンプルの生成
- データの多様性を向上
- 過学習リスクの軽減
- 決定境界の一般化能力の向上

**アルゴリズムの仕組み:**
1. 少数クラスの各サンプルについて、k個の最近傍を特定
2. ランダムに選択した最近傍との間で新しいサンプルを生成
3. 元のサンプルと選択した最近傍の間をランダムに補間
4. 生成したサンプルを少数クラスに追加

**実装方法:**
```python
# imbalanced-learn を使用した実装例
from imblearn.over_sampling import SMOTE
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
```

**SMOTE のバリエーション:**
- Borderline-SMOTE: 決定境界付近のサンプルに焦点
- ADASYN: 学習が困難なサンプル付近で多くの合成サンプルを生成
- SVM-SMOTE: SVM を使用して決定境界を特定
- KMeans-SMOTE: クラスタリングを使用して多様なサンプル生成
- SMOTE-NC: 数値と名義特徴の混合データに対応

**考慮事項:**
- 特徴空間の密度が低い領域での不適切なサンプル生成
- 高次元データでの「次元の呪い」の影響
- カテゴリ変数の取り扱い
- パラメータ（k値）の選択
- 外れ値の影響

**ユースケース:**
- 画像認識での少数クラスの強化
- 医療データ分析（希少疾患の検出）
- 不正検知システム
- 顧客行動予測
- テキスト分類の不均衡データセット

## クラス不均衡
データセット内の異なるクラスのサンプル数に大きな差がある状態です。多くの機械学習アルゴリズムが多数クラスに偏った予測をする原因となります。

**主な特徴:**
- クラス間のサンプル数の大きな差異
- 少数クラスの検出精度低下
- 多数クラスへの予測バイアス
- 標準的な評価指標の信頼性低下
- モデルの一般化能力への悪影響

**クラス不均衡の影響:**
- 多数クラスに偏った予測
- 少数クラスの誤分類率の増加
- 精度（Accuracy）指標の誤解を招く高さ
- 決定境界の偏り
- モデルの実用性低下

**対処戦略:**
1. **データレベルの手法:**
   - オーバーサンプリング（SMOTE など）
   - アンダーサンプリング
   - ハイブリッドサンプリング（SMOTETomek など）
   - データ拡張（Data Augmentation）

2. **アルゴリズムレベルの手法:**
   - コスト敏感学習（Cost-sensitive Learning）
   - クラス重み付け
   - 閾値調整
   - 異常検知アプローチ

3. **アンサンブル手法:**
   - バランスドランダムフォレスト
   - EasyEnsemble
   - RUSBoost
   - SMOTEBoost

**評価指標の選択:**
- 精度（Accuracy）よりも F1スコア、AUC-ROC、AUC-PR を優先
- 再現率（Recall）と適合率（Precision）のバランス
- 混同行列（Confusion Matrix）の詳細分析
- クラス別性能指標の確認
- コスト考慮型評価指標

**AWS での実装オプション:**
- SageMaker の組み込みアルゴリズムでのクラス重み設定
- SageMaker Processing ジョブでのデータバランシング
- SageMaker Clarify でのバイアス検出と軽減
- AWS Glue ETL ジョブでのデータ変換
- カスタムトレーニングスクリプトでの実装

**ユースケース:**
- 不正検知（少数の不正トランザクション）
- 医療診断（希少疾患の検出）
- 顧客解約予測（少数の解約顧客）
- 製造での欠陥検出（少数の不良品）
- 異常検知（少数の異常イベント）
- リスク管理（少数の高リスクケース）
