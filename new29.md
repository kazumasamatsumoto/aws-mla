# AWS機械学習関連用語解説

## Amazon SageMaker Pipelines
機械学習ワークフローを自動化するためのCI/CDサービスです。再現可能なパイプラインを構築できます。モデル開発のすべてのステップを定義、自動化、管理するための最初のMLに特化したCI/CDサービスです。

**主な特徴:**
- DAG（有向非巡回グラフ）ベースのワークフロー定義
- パイプラインの各ステップの並列実行と依存関係管理
- パラメータ化されたパイプラインテンプレート
- パイプライン実行の自動トリガー（スケジュール、イベント）
- パイプラインの再実行と比較機能
- SageMaker Studio との統合によるビジュアル監視

**パイプラインステップの種類:**
- データ処理（Processing）
- モデルトレーニング（Training）
- モデル評価（Condition）
- モデル登録（RegisterModel）
- モデルデプロイ（CreateModel）
- カスタムステップ（Lambda 関数など）

**ユースケース:**
- エンドツーエンドの ML ワークフローの自動化
- 複数環境（開発、テスト、本番）間のモデル昇格
- モデル再トレーニングの自動化と A/B テスト
- 規制要件に準拠したモデル開発プロセスの標準化
- チーム間の ML プロセスの共有と再利用

## SageMaker Studio
機械学習モデルの構築、トレーニング、デプロイ、分析のための統合開発環境（IDE）です。データサイエンティストとMLエンジニアのための包括的なワークスペースを提供します。

**主な特徴:**
- Jupyter ノートブックの拡張機能と共同編集
- コードレスのビジュアルインターフェース（AutoML、Data Wrangler など）
- 実験の追跡と比較
- モデルのデバッグとプロファイリング
- 分散トレーニングの設定と監視
- モデルのデプロイと監視の統合管理

**主要コンポーネント:**
- JupyterLab ベースの IDE
- SageMaker Experiments
- SageMaker Debugger
- SageMaker Model Monitor
- SageMaker Feature Store
- SageMaker Pipelines

**ユースケース:**
- チーム全体での ML プロジェクト管理
- 迅速なプロトタイピングから本番デプロイまでの一貫した環境
- 複数のモデルバージョンの比較と評価
- モデルパフォーマンスの継続的な監視と改善
- 組織全体での ML ベストプラクティスの標準化

## SageMaker ML Lineage Tracking
機械学習ワークフローの各ステップを追跡し、モデルの系統（データセット、アルゴリズム、ハイパーパラメータなど）を記録する機能です。モデルの透明性、再現性、監査可能性を確保します。

**主な特徴:**
- データセット、アルゴリズム、ハイパーパラメータの追跡
- モデルのバージョン管理と系統図の自動生成
- トレーニングジョブとデプロイの関連付け
- カスタムメタデータとタグ付け
- クエリ可能な系統グラフ

**追跡される主要エンティティ:**
- 試行（Trial）：実験の個々の実行
- 試行コンポーネント（TrialComponent）：処理、トレーニング、変換ジョブ
- アーティファクト（Artifact）：データセット、モデルなどの入出力
- コンテキスト（Context）：エンドポイント、パイプラインなどの論理グループ
- アクション（Action）：ワークフロー内の処理ステップ

**ユースケース:**
- 規制コンプライアンス（GDPR、HIPAA など）の証明
- モデルの再現と監査
- 問題発生時の根本原因分析
- モデル開発プロセスの最適化
- チーム間のナレッジ共有と協業

## AWS CodePipeline
アプリケーションやインフラストラクチャの更新を継続的に提供するためのCI/CDサービスです。MLワークフローの自動化にも使用できます。コード変更からモデルデプロイまでの自動化パイプラインを構築できます。

**主な特徴:**
- ビジュアルワークフローエディタ
- 複数のソースリポジトリとの統合（GitHub、CodeCommit など）
- 並列アクションと承認ステップ
- カスタムアクションとプラグイン
- AWS のサービスとの緊密な統合
- イベント駆動型のパイプライン実行

**ML関連の統合:**
- SageMaker モデルのビルドとデプロイ
- AWS Lambda によるカスタム ML 処理
- AWS Step Functions による複雑な ML ワークフロー
- Amazon ECR でのコンテナイメージ管理
- CloudFormation によるインフラストラクチャのプロビジョニング

**ユースケース:**
- ML モデルの継続的インテグレーションとデプロイ
- コードとモデルの変更に基づく自動テストと検証
- 複数環境（開発、ステージング、本番）へのモデル昇格
- インフラストラクチャとアプリケーションの同期デプロイ
- 承認ワークフローを含むガバナンスプロセスの自動化

## SageMaker Experiments
機械学習実験を追跡、比較、評価するためのツールです。異なるモデルバージョンやハイパーパラメータの結果を管理します。実験の再現性と組織化を実現します。

**主な特徴:**
- 実験、試行、パラメータの階層的管理
- 自動メトリクスの追跡と可視化
- 複数の試行の並列比較
- タグとメタデータによる検索と分類
- SageMaker Studio との統合
- 実験の再現と共有

**追跡される情報:**
- ハイパーパラメータ設定
- 評価メトリクス（精度、損失など）
- 入力データセットと前処理ステップ
- モデルアーキテクチャとパラメータ
- 環境設定（インスタンスタイプなど）
- カスタムタグとメタデータ

**ユースケース:**
- ハイパーパラメータ最適化の追跡と比較
- モデルアーキテクチャの実験と評価
- チーム間での実験結果の共有と協業
- 最適なモデルの特定と本番環境への昇格
- 過去の実験の再現と検証
- 実験結果の文書化とレポート作成
