# Amazon SageMaker 非同期推論の概要

Amazon SageMaker 非同期推論（Asynchronous Inference）は、予測リクエストを非同期で処理する SageMaker の機能です。大きなペイロードや長時間実行される推論を効率的に処理するために設計されています。

## 主な特徴

- **大きなペイロードの処理**: 最大 1GB のリクエストペイロードをサポート
- **長時間実行される推論**: タイムアウト制限を気にせず、長時間かかる推論処理が可能
- **コスト最適化**: オンデマンドでインスタンスをスケールアップ/ダウンし、アイドル時にはゼロにスケールダウン
- **キューイングメカニズム**: Amazon SNS と Amazon SQS を使用したリクエストのキューイング
- **非同期ワークフロー**: リクエスト送信 → 処理 → 完了通知の非同期処理フロー

## ユースケース

- 大規模な画像や動画の処理
- 複雑な NLP（自然言語処理）タスク
- バッチ処理が必要な推論ワークロード
- 不規則なトラフィックパターンを持つアプリケーション
- コスト最適化が必要なシナリオ

## 実装方法

1. **エンドポイント作成**: 非同期推論用の SageMaker エンドポイントを設定
2. **通知設定**: Amazon SNS トピックを設定して処理完了通知を受け取る
3. **呼び出し**: `InvokeEndpointAsync` API を使用してリクエストを送信
4. **結果取得**: 処理完了後、Amazon S3 から結果を取得

## 利点

- リアルタイム推論と比較して、大きなデータや長時間処理に適している
- スケーラビリティとコスト効率に優れている
- トラフィックの急増に柔軟に対応できる
- バックエンドシステムへの負荷を軽減

SageMaker 非同期推論は、リアルタイム性が厳しく求められないが、大規模なデータ処理能力が必要な AI アプリケーションに最適なソリューションです。

# Amazon SageMaker リアルタイム推論の概要

Amazon SageMaker リアルタイム推論は、低レイテンシーでインタラクティブなリクエストに対応するための推論方法です。エンドユーザーからのリクエストにリアルタイムで応答する必要があるアプリケーションに最適です。

## 主な特徴

- **低レイテンシー**: ミリ秒単位の応答時間を実現
- **常時稼働**: エンドポイントは常に稼働状態を維持
- **自動スケーリング**: トラフィックに応じてインスタンス数を自動調整
- **高可用性**: 複数のアベイラビリティーゾーンにわたるデプロイをサポート
- **同期処理**: リクエストを送信し、即座に応答を受け取る同期処理モデル

## ユースケース

- ウェブアプリケーションやモバイルアプリのリアルタイム予測
- オンラインレコメンデーションシステム
- リアルタイム詐欺検出
- インタラクティブなチャットボットや対話型 AI
- 即時応答が必要なビジネスアプリケーション

## 実装方法

1. **モデルのデプロイ**: SageMaker コンソールまたは API を使用してモデルをエンドポイントにデプロイ
2. **エンドポイント設定**: インスタンスタイプと数の選択、オートスケーリング設定
3. **呼び出し**: `InvokeEndpoint` API を使用して同期的にリクエストを送信
4. **応答取得**: リクエストに対する応答をリアルタイムで受け取る

## 考慮事項

- **コスト**: エンドポイントは常時稼働するため、使用量に関わらず料金が発生
- **タイムアウト制限**: デフォルトで 60 秒のタイムアウト制限あり
- **ペイロードサイズ**: 最大 6MB（リクエスト・レスポンス合計）の制限
- **スケーリング遅延**: 突発的なトラフィック増加に対応する際にスケーリングの遅延が発生する可能性

リアルタイム推論は、即時の応答が必要なユースケースに適していますが、大きなペイロードや長時間実行される処理には非同期推論やバッチ変換の使用を検討すべきです。

# Amazon SageMaker サーバーレス推論の概要

Amazon SageMaker サーバーレス推論は、インフラストラクチャの管理なしで機械学習モデルをデプロイできる SageMaker の機能です。サーバーレスコンピューティングの利点を ML 推論に適用し、オンデマンドでスケールする自動化されたエンドポイントを提供します。

## 主な特徴

- **サーバー管理不要**: インフラストラクチャのプロビジョニングや管理が不要
- **自動スケーリング**: トラフィックに応じて自動的にスケールアップ/ダウン（ゼロを含む）
- **使用量ベースの課金**: 実際の推論処理時間に対してのみ課金
- **簡素化されたデプロイ**: 数回のクリックまたは API 呼び出しでデプロイ可能
- **メモリサイズ設定**: 用途に応じて 1GB〜6GB のメモリサイズを選択可能

## ユースケース

- トラフィックパターンが不規則なアプリケーション
- 開発環境やテスト環境
- 低頻度の推論リクエスト
- コスト最適化が重要なプロジェクト
- 小〜中規模のモデルデプロイ

## 実装方法

1. **エンドポイント設定**: SageMaker コンソールまたは SDK でサーバーレスエンドポイントを設定
2. **メモリ設定**: モデルの要件に基づいてメモリサイズを選択
3. **同時実行数設定**: 必要に応じて最大同時実行数を設定
4. **デプロイ**: サーバーレスエンドポイントにモデルをデプロイ
5. **呼び出し**: 標準の`InvokeEndpoint` API を使用して推論リクエストを送信

## 利点と制約

### 利点

- 管理オーバーヘッドの削減
- アイドル時のコスト削減（ゼロインスタンス時に料金発生なし）
- 自動スケーリングによる柔軟性
- スタートアップ時間の短縮（特にウォームプール使用時）

### 制約

- 最大タイムアウト: 60 秒
- 最大ペイロードサイズ: 4MB
- 利用可能なメモリ: 最大 6GB
- 一部の特殊なモデルやフレームワークでは使用できない場合がある

サーバーレス推論は、変動するワークロードや開発/テスト環境、コスト効率を重視するユースケースに特に適しています。リアルタイム推論と非同期推論の中間に位置する選択肢として、インフラストラクチャ管理の複雑さなしに柔軟な推論機能を提供します。

# Amazon SageMaker バッチ変換の概要

Amazon SageMaker バッチ変換は、大量のデータセットに対して一括して予測を実行するための SageMaker の機能です。リアルタイム応答が不要で、大規模なデータセット全体に対して予測を実行する場合に最適です。

## 主な特徴

- **大規模データ処理**: 数 GB〜数 TB の大規模データセットを効率的に処理
- **一括処理**: 単一のジョブとして大量のデータに対して推論を実行
- **S3 ベース**: 入力データと出力データを S3 バケットで管理
- **分散処理**: 複数のインスタンスでデータを並列処理可能
- **ジョブベース**: エンドポイントではなくジョブとして実行

## ユースケース

- 定期的な予測生成（日次、週次、月次の一括処理）
- 大規模なデータセットのラベリング
- オフライン推論
- データ変換パイプライン
- モデル評価やテスト

## 実装方法

1. **入力データの準備**: データを S3 バケットにアップロード（CSV、JSON、RecordIO、TFRecord 等）
2. **バッチジョブの設定**: インスタンスタイプと数、入出力設定を指定
3. **ジョブの実行**: `CreateTransformJob` API を呼び出してバッチ変換ジョブを開始
4. **結果取得**: 処理完了後、S3 バケットから結果を取得

## 最適化オプション

- **MaxPayloadInMB**: 単一リクエストの最大ペイロードサイズを設定
- **MaxConcurrentTransforms**: 同時実行される変換の最大数を指定
- **BatchStrategy**: 単一/複数レコードバッチ戦略の選択
- **Split/Assemble 機能**: 入力データの分割と出力データの結合
- **インスタンス数**: 並列処理のためのコンピューティングリソース調整

## リアルタイム推論との比較

| 機能         | バッチ変換                 | リアルタイム推論         |
| ------------ | -------------------------- | ------------------------ |
| 処理形態     | 一括                       | 個別リクエスト           |
| インフラ     | 一時的（ジョブ完了後終了） | 永続的（常時稼働）       |
| レイテンシー | 高（分〜時間）             | 低（ミリ秒〜秒）         |
| コスト効率   | 大規模データに効率的       | 頻繁なリクエストに効率的 |
| スケーリング | ジョブ単位で設定           | 自動スケーリング         |

バッチ変換は、リアルタイム性よりも処理能力と効率性を重視するシナリオに最適なソリューションです。大量のデータを一度に処理する需要がある場合や、定期的な予測生成が必要な場合に特に有用です。

![[Pasted image 20250301085639.png]]

# Amazon SageMaker Model Monitor の概要

Amazon SageMaker Model Monitor は、本番環境にデプロイされた機械学習モデルを継続的にモニタリングするための SageMaker の機能です。データドリフトやモデルの品質低下を自動的に検出し、モデルのパフォーマンスを維持するのに役立ちます。

## 主なモニタリングタイプ

1. **データ品質モニタリング**: 入力データの統計的プロパティの変化を検出
2. **モデル品質モニタリング**: 予測精度などのモデルパフォーマンス指標を追跡
3. **バイアスドリフトモニタリング**: 本番データにおけるバイアスの変化を検出
4. **特徴量重要度ドリフトモニタリング**: 特徴量の相対的重要度の変化を追跡

## 主な機能

- **自動ベースライン作成**: トレーニングデータやモデルから自動的にベースラインを生成
- **スケジュールされたモニタリング**: 定期的なモニタリングジョブを自動実行
- **制約と統計の生成**: データセットの統計情報と制約条件を自動生成
- **アラート通知**: しきい値を超えた場合に Amazon CloudWatch を通じて通知
- **可視化**: Amazon SageMaker Studio でモニタリングレポートを Visual 化

## 実装方法

1. **ベースラインの作成**: トレーニングデータを使用してベースラインを確立
2. **モニタリングスケジュールの設定**: モニタリングの頻度と対象を設定
3. **しきい値の設定**: アラートをトリガーするしきい値を定義
4. **通知の設定**: CloudWatch アラームと SNS 通知を設定
5. **結果の分析**: SageMaker Studio でモニタリング結果を確認

## 利点

- **自動化**: モデルのドリフト検出を自動化し、手動監視の必要性を低減
- **早期発見**: 問題を早期に発見し、修正アクションを迅速に実施可能
- **コンプライアンス**: モデルの品質とパフォーマンスの継続的な記録を維持
- **ML Ops 統合**: SageMaker の MLOps パイプラインとシームレスに統合
- **説明可能性**: モデルの動作を時間経過とともに追跡・説明可能

## ユースケース

- 金融サービスにおける詐欺検出モデルのモニタリング
- 小売業における需要予測モデルの精度追跡
- ヘルスケアにおける診断モデルのバイアスモニタリング
- マーケティングにおける顧客行動予測モデルのドリフト検出
- 製造業における予知保全モデルの品質管理

SageMaker Model Monitor は、本番環境での ML モデルの信頼性と品質を維持するための重要なツールであり、MLOps プラクティスの中核的な要素として機能します。モデルのライフサイクル全体を通じた継続的なモニタリングと改善を促進します。

# Amazon SageMaker Model Registry について

Amazon SageMaker Model Registry は、機械学習モデルの管理、バージョン管理、および展開を効率化するためのサービスです。以下に主要な特徴と機能をまとめます。

## 主な特徴

- **モデルのバージョン管理**: モデルの異なるバージョンを一元管理し、履歴を追跡できます
- **モデルメタデータの保存**: モデルの性能指標、パラメータ、データセット情報などのメタデータを記録できます
- **承認ワークフロー**: モデルの承認プロセスを自動化し、本番環境への展開を管理できます
- **モデルの系統追跡**: モデルがどのデータセットで訓練されたか、どのアルゴリズムが使用されたかなどの系統情報を記録します
- **タグ付けとグループ化**: モデルをタグ付けして分類し、検索や整理を容易にします

## 主な利点

- **ガバナンスの向上**: モデル開発から展開までの追跡性と監査性を確保します
- **コラボレーションの効率化**: チーム間でモデルの共有と再利用が容易になります
- **デプロイの迅速化**: 承認済みモデルをより迅速に本番環境に展開できます
- **コンプライアンスの強化**: 規制要件に準拠したモデル管理が可能です

## 使用方法

1. **モデルグループの作成**: 関連するモデルバージョンをグループ化します
2. **モデルバージョンの登録**: 訓練済みモデルをレジストリに登録します
3. **モデルの評価と承認**: 登録されたモデルを評価し、承認ステータスを更新します
4. **モデルのデプロイ**: 承認済みモデルを本番環境にデプロイします

## 統合サービス

- SageMaker Pipelines
- SageMaker Experiments
- SageMaker Endpoints
- AWS Step Functions
- Amazon EventBridge

Model Registry は、MLOps（機械学習オペレーション）を実践する組織にとって、モデルのライフサイクル管理を効率化し、信頼性の高い AI システムの構築を支援する重要なコンポーネントです。

# Amazon SageMaker Canvas について

Amazon SageMaker Canvas は、コーディングなしで機械学習モデルを構築・利用できるビジュアルインターフェースを提供するサービスです。データサイエンスやプログラミングの専門知識がなくてもビジネスアナリストやドメインエキスパートが機械学習の力を活用できるように設計されています。

## 主な特徴

- **ノーコード開発環境**: ドラッグ&ドロップのインターフェースでモデル構築が可能
- **データ接続の容易さ**: Amazon S3、各種データベース、ローカルファイルなど多様なデータソースに接続可能
- **自動モデル構築**: 最適なアルゴリズムと設定を自動的に選択・適用
- **予測結果の即時確認**: モデルのパフォーマンスとその予測結果をリアルタイムで可視化
- **カスタムモデルのインポート**: 既存のデータサイエンティストが構築したモデルを取り込み可能

## サポートされる用途

- **数値予測**: 売上予測、在庫最適化、価格最適化など
- **カテゴリ予測**: 顧客セグメンテーション、離脱予測、詐欺検出など
- **時系列予測**: 需要予測、季節トレンド分析など
- **画像分類**: 製品欠陥検出、画像認識タスクなど
- **テキスト分析**: 感情分析、テキスト分類、エンティティ抽出など
- **生成 AI**: テキスト生成、要約、翻訳などの基盤モデル活用

## 主な利点

- **ML 導入の加速**: 専門知識不要でモデル構築から数日〜数週間を数時間に短縮
- **ビジネス価値の迅速な創出**: 分析・予測結果をすぐにビジネス意思決定に活用可能
- **リソース最適化**: データサイエンティストのリソースをより複雑な課題に集中させることが可能
- **セキュリティ・ガバナンス**: AWS のセキュリティ機能と SageMaker のガバナンス体制を活用

## 統合機能

- **SageMaker との連携**: Canvas 上で作成したモデルを SageMaker Studio と共有可能
- **Ready-to-use モデル**: Amazon Rekognition、Amazon Textract、Amazon Comprehend などのサービスと統合
- **基盤モデル統合**: Amazon Bedrock、Anthropic Claude、Stability AI などの生成 AI モデルを統合

SageMaker Canvas は、ビジネスアナリストやドメインエキスパートが機械学習の障壁を下げ、データドリブンな意思決定を加速させるための効果的なツールとして機能します。

# Apache Parquet について

Apache Parquet は、効率的なデータストレージと処理のために設計されたオープンソースの列指向データファイル形式です。ビッグデータエコシステムで広く採用されており、特に分析ワークロードに最適化されています。

## 主な特徴

- **列指向ストレージ**: データを行ではなく列ごとに格納するため、特定の列のみを必要とするクエリが効率的
- **効率的な圧縮**: データ型ごとに最適化された圧縮アルゴリズムを適用し、ストレージスペースを削減
- **エンコーディングスキーム**: ランレングスエンコーディング、ディクショナリエンコーディングなどの手法でデータ圧縮を強化
- **スキーマ埋め込み**: データとともにスキーマが保存されるため、自己記述的なフォーマット
- **ネストされたデータ構造**: 複雑なデータ型や階層構造をサポート

## 主な利点

- **クエリパフォーマンスの向上**: 必要な列のみを読み込むことで、I/O を大幅に削減
- **ストレージコストの削減**: 効率的な圧縮により、ストレージ使用量が少ない
- **処理速度の向上**: 列指向形式と圧縮により、スキャンと集計操作が高速化
- **エコシステム互換性**: Hadoop、Spark、Hive、Presto など多くのビッグデータツールとシームレスに連携

## 技術的詳細

- **ファイル構造**: ヘッダー、データブロック、フッターで構成
- **データページ**: 各列のデータは複数のページに分割され、個別に圧縮・エンコード
- **統計メタデータ**: 各データページには統計情報が含まれ、クエリプランナーが不要なブロックをスキップするのに役立つ
- **サポートデータ型**: 基本型（整数、浮動小数点、ブール値、バイナリ、文字列）、論理型、複合型

## 一般的なユースケース

- **データウェアハウス**: 大規模なデータ分析ワークロード
- **データレイク**: 構造化・半構造化データの効率的な保存
- **機械学習**: トレーニングデータセットの保存と読み込み
- **ETL パイプライン**: データ変換ワークフローでの中間形式

Apache Parquet は、特に分析クエリパターンでその威力を発揮し、大規模データ処理において高いパフォーマンスと効率性を実現するデータ形式です。

# Snappy で圧縮された CSV ファイル

Snappy で圧縮された CSV ファイルは、標準の CSV（カンマ区切り値）データを Snappy 圧縮アルゴリズムで圧縮したファイル形式です。以下にその主な特徴と利点をまとめます。

## Snappy 圧縮アルゴリズム

- **開発元**: Google が開発したオープンソースの圧縮アルゴリズム
- **設計思想**: 高速な圧縮・展開速度を優先し、圧縮率は適度なレベルで妥協
- **使用目的**: 処理速度が重要なビッグデータ環境での利用に最適化

## 主な特徴

- **高速な圧縮・展開**: 他の多くの圧縮アルゴリズム（GZIP など）と比較して非常に高速
- **適度な圧縮率**: 通常、元の CSV ファイルの約 30-50%程度のサイズに圧縮
- **ファイル拡張子**: 一般的に`.csv.snappy`または`.csv.sz`が使用される
- **可逆圧縮**: データ損失なく完全に元の CSV に復元可能

## 利点

- **ストレージ削減**: 生の CSV ファイルと比較してディスク使用量を削減
- **転送時間短縮**: ネットワーク経由でのデータ転送時間を短縮
- **処理オーバーヘッド低減**: 展開処理が高速なため、データ処理パイプラインでのボトルネックが軽減
- **メモリ使用効率**: 圧縮データをメモリに保持することで、メモリ使用効率が向上

## 一般的なユースケース

- **ビッグデータ処理**: Hadoop、Spark、Flink などのビッグデータフレームワークでの利用
- **データパイプライン**: ETL プロセスでの中間データ形式
- **ログファイル**: 大量のログデータの保存と転
